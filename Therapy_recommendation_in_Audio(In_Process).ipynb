{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries\n"
      ],
      "metadata": {
        "id": "5FGmqndEULxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJfJTo4jLNJC"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio numpy\n",
        "pip install --upgrade transformers accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our modal consists of two parts:\n",
        "\n",
        "**Stuttering Detection**: This part utilizes a Distilled Hubert model to **detect stuttering in speech**.\n",
        "\n",
        "**Therapy Recommendation System**: The second part of the modal uses 'facebook/mms-tts-eng' to provides **recommendations for therapy** based on the type of stuttering detected."
      ],
      "metadata": {
        "id": "4_0Z47pCXV3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stuttering Detection"
      ],
      "metadata": {
        "id": "pFrTxwfKVD9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        " The Stuttering Detection module aims to analyze audio inputs and classify them into distinct types of stuttering, namely Prolongation, Repetition, and Blocks, or classify them as Non-Stuttered speech.\n",
        "\n",
        "**Input:**\n",
        " Audio recordings of speech provided by the user.\n",
        "\n",
        "**Processing Steps:**\n",
        "\n",
        "The module preprocesses the audio input to extract relevant features for analysis.\n",
        "Utilizing transformers, the module analyzes the audio features to identify patterns indicative of different types of stuttering.\n",
        "Based on the extracted features and analysis, the module classifies the speech into one of the following categories: Prolongation, Repetition, Blocks, or Non-Stuttered speech.\n",
        "\n",
        "**Output:**\n",
        "\n",
        "The module provides feedback to the user regarding the type of stuttering detected in their speech.\n",
        "If the input speech exhibits characteristics of Prolongation, Repetition, or Blocks, the module informs the user accordingly.\n",
        "In cases where no stuttering is detected, the module classifies the speech as Non-Stuttered."
      ],
      "metadata": {
        "id": "CfZmfce_Vt1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launching our Stuttering Detection Modal\n",
        "import gradio as gr\n",
        "gr.load(\"models/HareemFatima/distilhubert-finetuned-stutterdetection\").launch()"
      ],
      "metadata": {
        "id": "KKIuOABXLVDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Theraoy Recommendation System"
      ],
      "metadata": {
        "id": "rXAgSBfNXpzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Therapy Recommendation part of our system, we leverage Generative AI technology to enhance the user experience. Specifically, we employ a Generative AI model to convert the recommended therapy, which is initially provided in text form, into audio files. This process allows users to receive therapy recommendations in spoken audio, providing a more immersive and accessible interaction.\n",
        "\n",
        "By harnessing Generative AI capabilities, we can dynamically generate natural-sounding audio representations of the therapy recommendations. This enables users to listen to the recommendations, which can be particularly beneficial for individuals who prefer auditory learning or have visual impairments.\n",
        "\n",
        "This integration of Generative AI in our Therapy Recommendation system enhances the accessibility and effectiveness of our modal, catering to a wider range of users and improving the overall user experience."
      ],
      "metadata": {
        "id": "bUGm-kkZYFe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VitsModel, AutoTokenizer\n",
        "import torch\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "# Load the model and tokenizer\n",
        "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
        "\n",
        "# Define the text and get inputs from the user\n",
        "print('''\n",
        "\n",
        "''')\n",
        "user_input = input('''Enter the type of stuttering :\n",
        "\n",
        "Press '1' for Prolongation Therapy\n",
        "Press '2' for Repetition Therapy\n",
        "Press '3' for Blocks Therapy\n",
        "\n",
        "''')\n",
        "\n",
        "  # Check user input and recommend therapy accordingly\n",
        "if user_input == '1':\n",
        "    text = '''prolongation:\n",
        "Hi there! Let's talk about how we can tackle prolongation stuttering. I've got some handy tips to share that can really make a difference for you. But first, let's understand what prolongation is all about. When you have prolongation stuttering, it means you tend to stretch out sounds or syllables when you speak, which can make your speech sound choppy. Now, let's dive into some therapy techniques that can help smooth out your speech.\"\n",
        "\n",
        "Therapy Recommendation for Prolongation Stuttering:\n",
        "\n",
        "The first approach is to Slow Down: Take your time when speaking and try to speak at a slower pace.\n",
        "The second approach is Breath Control: Focus on your breathing and take deep breaths before speaking to help maintain a steady flow of speech.\n",
        "The third approach is  Smooth Speech: Practice using gentle, smooth movements of your lips and tongue while speaking to reduce tension and improve fluency.\n",
        "The fourth technique can be Pacing: Break up your sentences into smaller chunks and pause slightly between phrases to enhance fluency.\n",
        "Lastly and most importantly incorporate relaxation exercises into your daily routine to reduce stress and tension, which can contribute to stuttering episodes.\n",
        "\n",
        "By following these steps you can surely make an effort in improving your speech Best of Luck!!\n",
        "'''\n",
        "\n",
        "    # Convert therapy recommendations to audio\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs).waveform\n",
        "\n",
        "elif user_input == '2':\n",
        "    text = '''Repetition:\n",
        "\n",
        "\"Hey there! Let's tackle repetition stuttering together. Before we dive into some helpful tips, let's understand what repetition is all about. Repetition stuttering happens when you find yourself repeating sounds, syllables, or even whole words when speaking, which can make your speech sound choppy or hesitant. Now, let's explore some therapy techniques to help smooth out your speech.\"\n",
        "\n",
        "Therapy Recommendation for Repetition Stuttering:\n",
        "\n",
        "First off, we have Slow Down: Take your time when speaking and try to speak at a slower pace to reduce the urge to repeat words or sounds.\n",
        "Next, try Chunking: Break up your sentences into smaller chunks and focus on speaking one chunk at a time, which can help minimize repetition.\n",
        "Another technique is Gentle Onset: Practice starting your words or phrases with a gentle, soft sound instead of a forceful one, which can help prevent repetition.\n",
        "Additionally, incorporate Relaxation Techniques: Integrate relaxation exercises into your daily routine to reduce tension and stress, which can contribute to stuttering.\n",
        "Lastly, remember to Practice Patience: Be patient with yourself as you work on improving your speech, and celebrate small victories along the way.\n",
        "\n",
        "With dedication and practice, you can make significant progress in reducing repetition stuttering. Keep up the good work!\"\n",
        "'''\n",
        "    # Convert therapy recommendations to audio\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs).waveform\n",
        "\n",
        "\n",
        "elif user_input == '3':\n",
        "    text ='''Blocks:\n",
        "\n",
        "\"Hello! Let's address block stuttering and explore some strategies to overcome it. But first, let's understand what block stuttering entails. Block stuttering occurs when you have difficulty starting or continuing a word or phrase, resulting in prolonged pauses or interruptions in your speech flow. Now, let's delve into some therapy techniques to help you navigate through block stuttering.\"\n",
        "\n",
        "Therapy Recommendation for Block Stuttering:\n",
        "\n",
        "One effective approach is Easy Onset: Focus on starting your words or phrases with a gentle, soft sound to ease into speaking and reduce the likelihood of blocks.\n",
        "The next approach is to Practice Gentle Movements: Work on using smooth and gentle movements of your lips and tongue while speaking to reduce tension and facilitate smoother speech production.\n",
        "Thirdly Use Pacing Techniques: Break up your sentences into smaller chunks and speak at a steady, even pace to maintain fluency and minimize blocks.\n",
        "Incorporate Breath Control: Pay attention to your breathing patterns and take deep breaths before speaking to relax your vocal cords and facilitate smoother speech.\n",
        "Lastly, Embrace Acceptance: Accept and embrace any blocks or interruptions in your speech without letting them discourage you. Remember, progress takes time and effort.\n",
        "\n",
        "By incorporating these techniques into your daily routine, you can gradually overcome block stuttering and improve your overall communication skills. Keep practicing and stay positive!\"\n",
        "'''\n",
        "     # Convert therapy recommendations to audio\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs).waveform\n",
        "\n",
        "    # Play the audio\n",
        "    #Audio(output, rate=22050)\n",
        "else:\n",
        "    print(\"Invalid input. Please enter 1, 2, or 3.\")\n",
        "\n",
        "output_slower = librosa.effects.time_stretch(output.numpy(), rate=1)  # Change the rate as needed\n",
        "\n",
        "# Display the slowed down audio\n",
        "Audio(output_slower, rate=model.config.sampling_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg8TQ66CLhO_",
        "outputId": "2603f06c-75e2-4d52-c0fb-5b45c1c96736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/mms-tts-eng were not used when initializing VitsModel: ['flow.flows.0.wavenet.in_layers.0.weight_g', 'flow.flows.0.wavenet.in_layers.0.weight_v', 'flow.flows.0.wavenet.in_layers.1.weight_g', 'flow.flows.0.wavenet.in_layers.1.weight_v', 'flow.flows.0.wavenet.in_layers.2.weight_g', 'flow.flows.0.wavenet.in_layers.2.weight_v', 'flow.flows.0.wavenet.in_layers.3.weight_g', 'flow.flows.0.wavenet.in_layers.3.weight_v', 'flow.flows.0.wavenet.res_skip_layers.0.weight_g', 'flow.flows.0.wavenet.res_skip_layers.0.weight_v', 'flow.flows.0.wavenet.res_skip_layers.1.weight_g', 'flow.flows.0.wavenet.res_skip_layers.1.weight_v', 'flow.flows.0.wavenet.res_skip_layers.2.weight_g', 'flow.flows.0.wavenet.res_skip_layers.2.weight_v', 'flow.flows.0.wavenet.res_skip_layers.3.weight_g', 'flow.flows.0.wavenet.res_skip_layers.3.weight_v', 'flow.flows.1.wavenet.in_layers.0.weight_g', 'flow.flows.1.wavenet.in_layers.0.weight_v', 'flow.flows.1.wavenet.in_layers.1.weight_g', 'flow.flows.1.wavenet.in_layers.1.weight_v', 'flow.flows.1.wavenet.in_layers.2.weight_g', 'flow.flows.1.wavenet.in_layers.2.weight_v', 'flow.flows.1.wavenet.in_layers.3.weight_g', 'flow.flows.1.wavenet.in_layers.3.weight_v', 'flow.flows.1.wavenet.res_skip_layers.0.weight_g', 'flow.flows.1.wavenet.res_skip_layers.0.weight_v', 'flow.flows.1.wavenet.res_skip_layers.1.weight_g', 'flow.flows.1.wavenet.res_skip_layers.1.weight_v', 'flow.flows.1.wavenet.res_skip_layers.2.weight_g', 'flow.flows.1.wavenet.res_skip_layers.2.weight_v', 'flow.flows.1.wavenet.res_skip_layers.3.weight_g', 'flow.flows.1.wavenet.res_skip_layers.3.weight_v', 'flow.flows.2.wavenet.in_layers.0.weight_g', 'flow.flows.2.wavenet.in_layers.0.weight_v', 'flow.flows.2.wavenet.in_layers.1.weight_g', 'flow.flows.2.wavenet.in_layers.1.weight_v', 'flow.flows.2.wavenet.in_layers.2.weight_g', 'flow.flows.2.wavenet.in_layers.2.weight_v', 'flow.flows.2.wavenet.in_layers.3.weight_g', 'flow.flows.2.wavenet.in_layers.3.weight_v', 'flow.flows.2.wavenet.res_skip_layers.0.weight_g', 'flow.flows.2.wavenet.res_skip_layers.0.weight_v', 'flow.flows.2.wavenet.res_skip_layers.1.weight_g', 'flow.flows.2.wavenet.res_skip_layers.1.weight_v', 'flow.flows.2.wavenet.res_skip_layers.2.weight_g', 'flow.flows.2.wavenet.res_skip_layers.2.weight_v', 'flow.flows.2.wavenet.res_skip_layers.3.weight_g', 'flow.flows.2.wavenet.res_skip_layers.3.weight_v', 'flow.flows.3.wavenet.in_layers.0.weight_g', 'flow.flows.3.wavenet.in_layers.0.weight_v', 'flow.flows.3.wavenet.in_layers.1.weight_g', 'flow.flows.3.wavenet.in_layers.1.weight_v', 'flow.flows.3.wavenet.in_layers.2.weight_g', 'flow.flows.3.wavenet.in_layers.2.weight_v', 'flow.flows.3.wavenet.in_layers.3.weight_g', 'flow.flows.3.wavenet.in_layers.3.weight_v', 'flow.flows.3.wavenet.res_skip_layers.0.weight_g', 'flow.flows.3.wavenet.res_skip_layers.0.weight_v', 'flow.flows.3.wavenet.res_skip_layers.1.weight_g', 'flow.flows.3.wavenet.res_skip_layers.1.weight_v', 'flow.flows.3.wavenet.res_skip_layers.2.weight_g', 'flow.flows.3.wavenet.res_skip_layers.2.weight_v', 'flow.flows.3.wavenet.res_skip_layers.3.weight_g', 'flow.flows.3.wavenet.res_skip_layers.3.weight_v', 'posterior_encoder.wavenet.in_layers.0.weight_g', 'posterior_encoder.wavenet.in_layers.0.weight_v', 'posterior_encoder.wavenet.in_layers.1.weight_g', 'posterior_encoder.wavenet.in_layers.1.weight_v', 'posterior_encoder.wavenet.in_layers.10.weight_g', 'posterior_encoder.wavenet.in_layers.10.weight_v', 'posterior_encoder.wavenet.in_layers.11.weight_g', 'posterior_encoder.wavenet.in_layers.11.weight_v', 'posterior_encoder.wavenet.in_layers.12.weight_g', 'posterior_encoder.wavenet.in_layers.12.weight_v', 'posterior_encoder.wavenet.in_layers.13.weight_g', 'posterior_encoder.wavenet.in_layers.13.weight_v', 'posterior_encoder.wavenet.in_layers.14.weight_g', 'posterior_encoder.wavenet.in_layers.14.weight_v', 'posterior_encoder.wavenet.in_layers.15.weight_g', 'posterior_encoder.wavenet.in_layers.15.weight_v', 'posterior_encoder.wavenet.in_layers.2.weight_g', 'posterior_encoder.wavenet.in_layers.2.weight_v', 'posterior_encoder.wavenet.in_layers.3.weight_g', 'posterior_encoder.wavenet.in_layers.3.weight_v', 'posterior_encoder.wavenet.in_layers.4.weight_g', 'posterior_encoder.wavenet.in_layers.4.weight_v', 'posterior_encoder.wavenet.in_layers.5.weight_g', 'posterior_encoder.wavenet.in_layers.5.weight_v', 'posterior_encoder.wavenet.in_layers.6.weight_g', 'posterior_encoder.wavenet.in_layers.6.weight_v', 'posterior_encoder.wavenet.in_layers.7.weight_g', 'posterior_encoder.wavenet.in_layers.7.weight_v', 'posterior_encoder.wavenet.in_layers.8.weight_g', 'posterior_encoder.wavenet.in_layers.8.weight_v', 'posterior_encoder.wavenet.in_layers.9.weight_g', 'posterior_encoder.wavenet.in_layers.9.weight_v', 'posterior_encoder.wavenet.res_skip_layers.0.weight_g', 'posterior_encoder.wavenet.res_skip_layers.0.weight_v', 'posterior_encoder.wavenet.res_skip_layers.1.weight_g', 'posterior_encoder.wavenet.res_skip_layers.1.weight_v', 'posterior_encoder.wavenet.res_skip_layers.10.weight_g', 'posterior_encoder.wavenet.res_skip_layers.10.weight_v', 'posterior_encoder.wavenet.res_skip_layers.11.weight_g', 'posterior_encoder.wavenet.res_skip_layers.11.weight_v', 'posterior_encoder.wavenet.res_skip_layers.12.weight_g', 'posterior_encoder.wavenet.res_skip_layers.12.weight_v', 'posterior_encoder.wavenet.res_skip_layers.13.weight_g', 'posterior_encoder.wavenet.res_skip_layers.13.weight_v', 'posterior_encoder.wavenet.res_skip_layers.14.weight_g', 'posterior_encoder.wavenet.res_skip_layers.14.weight_v', 'posterior_encoder.wavenet.res_skip_layers.15.weight_g', 'posterior_encoder.wavenet.res_skip_layers.15.weight_v', 'posterior_encoder.wavenet.res_skip_layers.2.weight_g', 'posterior_encoder.wavenet.res_skip_layers.2.weight_v', 'posterior_encoder.wavenet.res_skip_layers.3.weight_g', 'posterior_encoder.wavenet.res_skip_layers.3.weight_v', 'posterior_encoder.wavenet.res_skip_layers.4.weight_g', 'posterior_encoder.wavenet.res_skip_layers.4.weight_v', 'posterior_encoder.wavenet.res_skip_layers.5.weight_g', 'posterior_encoder.wavenet.res_skip_layers.5.weight_v', 'posterior_encoder.wavenet.res_skip_layers.6.weight_g', 'posterior_encoder.wavenet.res_skip_layers.6.weight_v', 'posterior_encoder.wavenet.res_skip_layers.7.weight_g', 'posterior_encoder.wavenet.res_skip_layers.7.weight_v', 'posterior_encoder.wavenet.res_skip_layers.8.weight_g', 'posterior_encoder.wavenet.res_skip_layers.8.weight_v', 'posterior_encoder.wavenet.res_skip_layers.9.weight_g', 'posterior_encoder.wavenet.res_skip_layers.9.weight_v']\n",
            "- This IS expected if you are initializing VitsModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing VitsModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of VitsModel were not initialized from the model checkpoint at facebook/mms-tts-eng and are newly initialized: ['flow.flows.0.wavenet.in_layers.0.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.0.parametrizations.weight.original1', 'flow.flows.0.wavenet.in_layers.1.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.1.parametrizations.weight.original1', 'flow.flows.0.wavenet.in_layers.2.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.2.parametrizations.weight.original1', 'flow.flows.0.wavenet.in_layers.3.parametrizations.weight.original0', 'flow.flows.0.wavenet.in_layers.3.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'flow.flows.0.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'flow.flows.0.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'flow.flows.0.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'flow.flows.0.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'flow.flows.0.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'flow.flows.1.wavenet.in_layers.0.parametrizations.weight.original0', 'flow.flows.1.wavenet.in_layers.0.parametrizations.weight.original1', 'flow.flows.1.wavenet.in_layers.1.parametrizations.weight.original0', 'flow.flows.1.wavenet.in_layers.1.parametrizations.weight.original1', 'flow.flows.1.wavenet.in_layers.2.parametrizations.weight.original0', 'flow.flows.1.wavenet.in_layers.2.parametrizations.weight.original1', 'flow.flows.1.wavenet.in_layers.3.parametrizations.weight.original0', 'flow.flows.1.wavenet.in_layers.3.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'flow.flows.1.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'flow.flows.1.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'flow.flows.1.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'flow.flows.1.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'flow.flows.1.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'flow.flows.2.wavenet.in_layers.0.parametrizations.weight.original0', 'flow.flows.2.wavenet.in_layers.0.parametrizations.weight.original1', 'flow.flows.2.wavenet.in_layers.1.parametrizations.weight.original0', 'flow.flows.2.wavenet.in_layers.1.parametrizations.weight.original1', 'flow.flows.2.wavenet.in_layers.2.parametrizations.weight.original0', 'flow.flows.2.wavenet.in_layers.2.parametrizations.weight.original1', 'flow.flows.2.wavenet.in_layers.3.parametrizations.weight.original0', 'flow.flows.2.wavenet.in_layers.3.parametrizations.weight.original1', 'flow.flows.2.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'flow.flows.2.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'flow.flows.2.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'flow.flows.2.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'flow.flows.2.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'flow.flows.2.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'flow.flows.2.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'flow.flows.2.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.0.parametrizations.weight.original0', 'flow.flows.3.wavenet.in_layers.0.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.1.parametrizations.weight.original0', 'flow.flows.3.wavenet.in_layers.1.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.2.parametrizations.weight.original0', 'flow.flows.3.wavenet.in_layers.2.parametrizations.weight.original1', 'flow.flows.3.wavenet.in_layers.3.parametrizations.weight.original0', 'flow.flows.3.wavenet.in_layers.3.parametrizations.weight.original1', 'flow.flows.3.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'flow.flows.3.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'flow.flows.3.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'flow.flows.3.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'flow.flows.3.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'flow.flows.3.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'flow.flows.3.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'flow.flows.3.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.0.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.0.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.1.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.1.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.10.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.10.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.11.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.11.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.12.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.12.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.13.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.13.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.14.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.14.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.15.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.15.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.2.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.2.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.3.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.3.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.4.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.4.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.5.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.5.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.6.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.6.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.7.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.7.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.8.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.8.parametrizations.weight.original1', 'posterior_encoder.wavenet.in_layers.9.parametrizations.weight.original0', 'posterior_encoder.wavenet.in_layers.9.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.0.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.0.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.1.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.1.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.10.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.10.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.11.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.11.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.12.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.12.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.13.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.13.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.14.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.14.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.15.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.15.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.2.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.2.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.3.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.3.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.4.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.4.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.5.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.5.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.6.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.6.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.7.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.7.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.8.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.8.parametrizations.weight.original1', 'posterior_encoder.wavenet.res_skip_layers.9.parametrizations.weight.original0', 'posterior_encoder.wavenet.res_skip_layers.9.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Enter the type of stuttering : \n",
            "\n",
            "Press '1' for Prolongation Therapy\n",
            "Press '2' for Repetition Therapy\n",
            "Press '3' for Blocks Therapy\n",
            "\n",
            "2\n"
          ]
        }
      ]
    }
  ]
}